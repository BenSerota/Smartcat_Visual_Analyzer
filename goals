let's build a real working prototype for visual segmentation.

my goal: take as input any PowerPoint file P, process it, and output optimal text segmentation for translation purposes. The segmentation should be informed by visual context analysis, not just textual rules.

for example: if a slide has two text boxes positioned side by side that visually form one title, they should be segmented together rather than separately. Traditional rule-based segmentation might treat them as separate segments, but visual analysis would recognize they form one cohesive unit.

the same applies to: bullet points that are visually grouped, captions that belong to images, or text elements that are visually related but separated by layout.

it is important to note that visual relationships are not always obvious from text alone. we need to use an LLM with visual analysis capabilities to understand the slide layout and text relationships.

to accomplish this, I am thinking the following solution:
1. have a PowerPoint file-upload page.
2. user uploads a .pptx file and clicks "analyze presentation".
3. system extracts text elements with positioning data and generates slide images.
4. GPT-5 Nano with visual analysis examines each slide image and:
   - identifies visual contexts (title groups, body text, captions, bullet lists, etc.)
   - understands relationships between text elements
   - suggests optimal segmentation boundaries based on visual layout
5. system combines textual rules with visual insights to create high-resolution segmentation.
6. user can review and edit the segmentation before exporting to XLIFF format.
